<!DOCTYPE html>
<html>
<head>
  <meta name="viewport" content="width=device-width, initial-scale=1">
	<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
	<link rel="stylesheet" href=""https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/github.min.css">
	<link rel="stylesheet" href="css/custom.css">
	<link rel="stylesheet" href="css/normalize.css">
  <title>This folder primarily contains auxiliary materials for our paper</title>
<style>
  table {
    width: 100%;
    border-collapse: collapse;
    text-align: center; /* 让所有单元格的内容居中 */
  }

  th, td {
    border: 1px solid #ccc; /* 灰色的竖线 */
    padding: 8px;
  }

  th {
    background-color: #f9f9f9;
  }

  audio {
    width: 130px;
  }

  .block-style {
    display: block;
    border: 2px solid #e1dede;
    box-shadow: 5px 5px 5px rgba(193, 192, 192, 0.763); /* 阴影效果 */
    padding: 10px;
    margin-top: 80px;
}
.center {
  text-align: center; /* 将 h2 文本居中 */
  box-shadow: 5px 5px 5px rgba(225, 224, 224, 0.95); /* 阴影效果 */
  padding: 10px;
}
.authorcenter {
  text-align: center; /* 将 h2 文本居中 */
}
.abstract {
  padding: 30px; /* 将 h2 文本居中 */
  word-wrap: break-word; /* 让长单词换行 */
}
</style>
<style>
  /* 只修改具有 custom-spacing 类的 p 标签和 ul 列表的间距 */
  .custom-spacing p {
      margin-bottom: 5px; /* 调整 p 标签的下边距 */
  }
  .custom-spacing ul {
      margin-top: 0; /* 去掉 ul 列表的上边距 */
  }
</style>
</head>
<body class="vscode-body vscode-light">
<ul>

  <div>
    <h1 class="authorcenter">A Controllable Emotion Voice Conversion Framework with Pre-trained Speech Representations</h1>
    <!-- <p class="authorcenter">Tianrui Wang$^1$, Meng Ge$^1$, Zhikang Niu$^2$, Chunyu Qiang$^1$, Cheng Gong$^1$, Ziyang Ma$^2$, Xiaobao Wang$^1$,\\Xie Chen$^2$, Longbiao Wang$^1$, Jianwu Dang$^3$</p> -->
    <p class="authorcenter">
      <br>
      Tianrui Wang<sup>1</sup>, Meng Ge<sup>1</sup>, Zhikang Niu<sup>2</sup>, Chunyu Qiang<sup>1</sup>, Cheng Gong<sup>1</sup>, Ziyang Ma<sup>2</sup>, Xiaobao Wang<sup>1</sup>,Xie Chen<sup>2</sup>, Longbiao Wang<sup>1</sup>, Jianwu Dang<sup>3</sup>  <br>
      <br>
      <sup>1</sup><em>Tianjin Key Laboratory of Cognitive Computing and Application, College of Intelligence and Computing, Tianjin University, Tianjin, China</em>
      <br>
      <sup>2</sup><em>MoE Key Lab of Artificial Intelligence, AI Institute, Shanghai Jiao Tong University, Shanghai, China</em>
      <br>
      <sup>3</sup><em>Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences, Guangdong, China</em>
  <p></p>
  <p class="abstract">
    <b>Abstract.</b> 
    Speech disentanglement is crucial for tasks like controllable speech synthesis, voice conversion, and speech emotion conversion. While many self-supervised or weak supervised speech pre-trained models have shown remarkable performance in speech recognition and speaker identification, their potential for speech disentanglement remains underexplored. Typically, speech pre-trained models used in speech synthesis focus on extracting strong task-specific representations, often overlooking their capacity for speech disentanglement in controllable speech generation. To address this gap, we propose a four-stage decoder model that integrates a speech disentanglement module, progressive generator, acoustic compensator, and flow predictor, leveraging the layer-wise task characteristics of pre-trained models and enabling controllable emotion and voice conversion with any pre-trained speech encoder. We evaluate this framework using six established speech pre-trained models, and experimental results demonstrate that several pre-trained models significantly outperform baseline methods within our framework on emotion and voice conversion. Moreover, our framework serves as a valuable benchmark for evaluating pre-trained models' capabilities in disentangling emotional state, speaker, and content from speech. We also release our code at <a href="https://github.com/wangtianrui/PM-EVC">https://github.com/wangtianrui/PM-EVC.</a>
  </div>

<div class="block-style">
  <h2 style="text-align: center">Model Overview</h2>
  <img src="./evc.jpg" alt="Audio Image 2" style="width: 60%; display: block; margin: 0 auto;" >
  <p style="text-align: center">Our four-stage emotional voice conversion framework, trained on self-supervised mel-spectrogram reconstruction, enables emotion and voice conversion (EVC), emotion conversion (EC), and voice conversion (VC) by altering emotional state or speaker representation during inference.</p>

</div>

<div class="block-style">
  <h2 style="text-align: center">Voice Conversion</h2>
  <p>
    Our framework employs ProgRE as the pre-trained model, <b>enabling stable voice conversion</b> while <b>preserving the original emotional state</b>.
    <br>
    <br>
  </p>
  <div class="english_vc_examples">
    <div class="english_vc active" data-page="1">
      <table class="table" style="margin-top: 20px;">
        <thead>
          <tr>
            <!-- 第一行，合并的cell -->
            <th colspan="3"></th> <!-- 合并Source Speech和Target Speaker的两列 -->
            <th colspan="6">24-layer Pre-trained Model Under Our Framework </th> <!-- 合并ProgRE到Whisper的六列 -->
            <th colspan="2">Baseline methods</th> <!-- 合并ConsistencyVC和Wav2vec-VC的两列 -->
        </tr>
          <tr>
            <th></th>
            <th>Source Speech</th>
            <th>Target Speaker</th>
            <th><b>ProgRE</b></th>
            <th><a >Data2vec</a></th>
            <th><a >HuBERT</a></th>
            <th><a >Wav2vec2.0</a></th>
            <th><a >WavLM</a></th>
            <th><a >Whisper</a></th>
            <th><a >ConsistencyVC</a></th>
            <th><a >Wav2vec-VC</a></th>
          </tr>
        </thead>
        <tbody id="">
          <tr>
            <th>Same emotion between<br>source and target</th>
            <td><audio src="./audios/vc/MSP-PODCAST_2927_0034.wav" controls="" style="width:130px"></audio></td>
            <td><audio src="./audios/vc/MSP-PODCAST_0083_0003.wav" controls="" style="width:130px"></audio></td>
            <td><audio src="./audios/vc/progre/283_MSP-PODCAST_2927_0034_srcspkmsp-1374_tgtspkmsp-285_srcemoneutral_tgtemoneutral.wav" controls="" style="width:130px"></audio></td>
            <td><audio src="./audios/vc/data2vec/283_MSP-PODCAST_2927_0034_srcspkmsp-1374_tgtspkmsp-285_srcemoneutral_tgtemoneutral.wav" controls="" style="width:130px"></audio></td>
            <td><audio src="./audios/vc/hubert/283_MSP-PODCAST_2927_0034_srcspkmsp-1374_tgtspkmsp-285_srcemoneutral_tgtemoneutral.wav" controls="" style="width:130px"></audio></td>
            <td><audio src="./audios/vc/wav2vec/283_MSP-PODCAST_2927_0034_srcspkmsp-1374_tgtspkmsp-285_srcemoneutral_tgtemoneutral.wav" controls="" style="width:130px"></audio></td>
            <td><audio src="./audios/vc/wavlm/283_MSP-PODCAST_2927_0034_srcspkmsp-1374_tgtspkmsp-285_srcemoneutral_tgtemoneutral.wav" controls="" style="width:130px"></audio></td>
            <td><audio src="./audios/vc/whisper/283_MSP-PODCAST_2927_0034_srcspkmsp-1374_tgtspkmsp-285_srcemoneutral_tgtemoneutral.wav" controls="" style="width:130px"></audio></td>
            <td><audio src="./audios/vc/consis_vc/283_MSP-PODCAST_2927_0034_srcspkmsp-1374_tgtspkmsp-285_srcemoneutral_tgtemoneutral.wav" controls="" style="width:130px"></audio></td>
            <td><audio src="./audios/vc/wav2vec_vc/283_MSP-PODCAST_2927_0034_srcspkmsp-1374_tgtspkmsp-285_srcemoneutral_tgtemoneutral.wav" controls="" style="width:130px"></audio></td>
          </tr>
          
        </tbody>
        <tbody id="">
          <tr>
            <th>Different emotion between<br>source and target</th>
            <td><audio src="./audios/sad_man.wav" controls="" style="width:130px"></audio></td>
            <td><audio src="./audios/happy_girl.wav" controls="" style="width:130px"></audio></td>
            <td><audio src="./audios/vc/progre/spk_cv_fbank.wav" controls="" style="width:130px"></audio></td>
            <td><audio src="./audios/vc/data2vec/spk_cv_fbank.wav" controls="" style="width:130px"></audio></td>
            <td><audio src="./audios/vc/hubert/spk_cv_fbank.wav" controls="" style="width:130px"></audio></td>
            <td><audio src="./audios/vc/wav2vec/spk_cv_fbank.wav" controls="" style="width:130px"></audio></td>
            <td><audio src="./audios/vc/wavlm/spk_cv_fbank.wav" controls="" style="width:130px"></audio></td>
            <td><audio src="./audios/vc/whisper/spk_cv_fbank.wav" controls="" style="width:130px"></audio></td>
            <td><audio src="./audios/vc/consis_vc/MSP-PODCAST_2894_0284_to_0016_000721.wav" controls="" style="width:130px"></audio></td>
            <td><audio src="./audios/vc/wav2vec_vc/spk_cv_fbank.wav" controls="" style="width:130px"></audio></td>
          </tr>
          
        </tbody>
      </table>
    </div>
  </div>
</div>

<!-- <hr style="height:10px;border:0px dashed #ffffff;" />
<hr style="height:1px;border:2px;border-top:2px dashed #555555;" /> -->

<div class="block-style">
  <h2 style="text-align: center">Emotion Conversion</h2>
  <p>
    Our framework employs ProgRE as the pre-trained model, <b>enabling stable global emotion state conversion</b> while <b>preserving the original speaker identification</b>.
    <br>
    <em>Please note that our emotional state is at utterance level and does not affect speech duration. Instead, it is primarily reflected in stress and pitch variations.</em>
    <br>
  </p>
  <div class="english_vc_examples">
    <div class="english_vc active" data-page="1">
      <table class="table" style="margin-top: 20px;">
        <thead>
          <tr>
            <!-- 第一行，合并的cell -->
            <th colspan="3"></th> <!-- 合并Source Speech和Target Speaker的两列 -->
            <th colspan="6">24-layer Pre-trained Model Under Our Framework</th> <!-- 合并ProgRE到Whisper的六列 -->
            <th colspan="2">Baseline methods</th> <!-- 合并ConsistencyVC和Wav2vec-VC的两列 -->
        </tr>
          <tr>
            <th> </th>
            <th>Source Speech</th>
            <th>Target Emotion</th>
            <th><b>ProgRE</b></th>
            <th><a >Data2vec</a></th>
            <th><a >HuBERT</a></th>
            <th><a >Wav2vec2.0</a></th>
            <th><a >WavLM</a></th>
            <th><a >Whisper</a></th>
            <th><a >ConsistencyVC</a></th>
            <th><a >Wav2vec-VC</a></th>
          </tr>
        </thead>
        <tbody id="">
          <tr>
            <th>Same speaker between<br>source and target</th>
            <td><audio src="./audios/ec/neutral_197_224_0200.wav" controls="" style="width:130px"></audio></td>
            <td><audio src="./audios/ec/anger_367-392_0372.wav" controls="" style="width:130px"></audio></td>
            <td><audio src="./audios/ec/progre/320_neutral_197_224_0200_srcspkemovdb-sam_tgtspkemovdb-sam_srcemoneutral_tgtemoangry.wav" controls="" style="width:130px"></audio></td>
            <td><audio src="./audios/ec/data2vec/320_neutral_197_224_0200_srcspkemovdb-sam_tgtspkemovdb-sam_srcemoneutral_tgtemoangry.wav" controls="" style="width:130px"></audio></td>
            <td><audio src="./audios/ec/hubert/320_neutral_197_224_0200_srcspkemovdb-sam_tgtspkemovdb-sam_srcemoneutral_tgtemoangry.wav" controls="" style="width:130px"></audio></td>
            <td><audio src="./audios/ec/wav2vec/320_neutral_197_224_0200_srcspkemovdb-sam_tgtspkemovdb-sam_srcemoneutral_tgtemoangry.wav" controls="" style="width:130px"></audio></td>
            <td><audio src="./audios/ec/wavlm/320_neutral_197_224_0200_srcspkemovdb-sam_tgtspkemovdb-sam_srcemoneutral_tgtemoangry.wav" controls="" style="width:130px"></audio></td>
            <td><audio src="./audios/ec/whisper/320_neutral_197_224_0200_srcspkemovdb-sam_tgtspkemovdb-sam_srcemoneutral_tgtemoangry.wav" controls="" style="width:130px"></audio></td>
            <td><audio src="./audios/ec/consis_vc/320_neutral_197_224_0200_srcspkemovdb-sam_tgtspkemovdb-sam_srcemoneutral_tgtemoangry.wav" controls="" style="width:130px"></audio></td>
            <td><audio src="./audios/ec/wav2vec_vc/320_neutral_197_224_0200_srcspkemovdb-sam_tgtspkemovdb-sam_srcemoneutral_tgtemoangry.wav" controls="" style="width:130px"></audio></td>
          </tr>
          
        </tbody>
        <tbody id="">
          <tr>
            <th>Different speaker between<br>source and target</th>
            <td><audio src="./audios/sad_man.wav" controls="" style="width:130px"></audio></td>
            <td><audio src="./audios/happy_girl.wav" controls="" style="width:130px"></audio></td>
            <td><audio src="./audios/ec/progre/emo_cv_fbank.wav" controls="" style="width:130px"></audio></td>
            <td><audio src="./audios/ec/data2vec/emo_cv_fbank.wav" controls="" style="width:130px"></audio></td>
            <td><audio src="./audios/ec/hubert/emo_cv_fbank.wav" controls="" style="width:130px"></audio></td>
            <td><audio src="./audios/ec/wav2vec/emo_cv_fbank.wav" controls="" style="width:130px"></audio></td>
            <td><audio src="./audios/ec/wavlm/emo_cv_fbank.wav" controls="" style="width:130px"></audio></td>
            <td><audio src="./audios/ec/whisper/emo_cv_fbank.wav" controls="" style="width:130px"></audio></td>
            <td><audio src="./audios/ec/consis_vc/MSP-PODCAST_2894_0284_to_0016_000721.wav" controls="" style="width:130px"></audio></td>
            <td><audio src="./audios/ec/wav2vec_vc/emo_cv_fbank.wav" controls="" style="width:130px"></audio></td>
          </tr>
          
        </tbody>
      </table>
    </div>
  </div>
</div>

<div class="block-style">
  <h2 style="text-align: center">Emotion and Voice Conversion</h2>
  <p>
    Our framework enables simultaneous <b>conversion of emotion and speaker</b>, with the <b>emotion and speaker originating from different speech samples.</b>
    <br>
    <br>
  </p>
  <div class="english_vc_examples">
    <div class="english_vc active" data-page="1">
      <table class="table" style="margin-top: 20px;">
        <thead>
          <tr>
            <!-- 第一行，合并的cell -->
            <th colspan="4"></th> <!-- 合并Source Speech和Target Speaker的两列 -->
            <th colspan="6">24-layer Pre-trained Model Under Our Framework</th> <!-- 合并ProgRE到Whisper的六列 -->
            <th colspan="2">Baseline methods</th> <!-- 合并ConsistencyVC和Wav2vec-VC的两列 -->
        </tr>
          <tr>
            <th></th>
            <th>Source Speech</th>
            <th>Target Emotion</th>
            <th>Target Speaker</th>
            <th><b>ProgRE</b></th>
            <th><a >Data2vec</a></th>
            <th><a >HuBERT</a></th>
            <th><a >Wav2vec2.0</a></th>
            <th><a >WavLM</a></th>
            <th><a >Whisper</a></th>
            <th><a >ConsistencyVC</a></th>
            <th><a >Wav2vec-VC</a></th>
          </tr>
        </thead>
        <tbody id="">
          <tr>
            <th>Same target of<br>emotion and speaker</th>
            <td><audio src="./audios/evc/028.wav" controls="" style="width:130px"></audio></td>
            <td><audio src="./audios/evc/017.wav" controls="" style="width:130px"></audio></td>
            <td><audio src="./audios/evc/017.wav" controls="" style="width:130px"></audio></td>
            <td><audio src="./audios/evc/progre/190_028_srcspkmead-M037_tgtspkmead-M033_srcemoangry_tgtemocontempt.wav" controls="" style="width:130px"></audio></td>
            <td><audio src="./audios/evc/data2vec/190_028_srcspkmead-M037_tgtspkmead-M033_srcemoangry_tgtemocontempt.wav" controls="" style="width:130px"></audio></td>
            <td><audio src="./audios/evc/hubert/190_028_srcspkmead-M037_tgtspkmead-M033_srcemoangry_tgtemocontempt.wav" controls="" style="width:130px"></audio></td>
            <td><audio src="./audios/evc/wav2vec/190_028_srcspkmead-M037_tgtspkmead-M033_srcemoangry_tgtemocontempt.wav" controls="" style="width:130px"></audio></td>
            <td><audio src="./audios/evc/wavlm/190_028_srcspkmead-M037_tgtspkmead-M033_srcemoangry_tgtemocontempt.wav" controls="" style="width:130px"></audio></td>
            <td><audio src="./audios/evc/whisper/190_028_srcspkmead-M037_tgtspkmead-M033_srcemoangry_tgtemocontempt.wav" controls="" style="width:130px"></audio></td>
            <td><audio src="./audios/evc/consis_vc/190_028_srcspkmead-M037_tgtspkmead-M033_srcemoangry_tgtemocontempt.wav" controls="" style="width:130px"></audio></td>
            <td><audio src="./audios/evc/wav2vec_vc/190_028_srcspkmead-M037_tgtspkmead-M033_srcemoangry_tgtemocontempt.wav" controls="" style="width:130px"></audio></td>
          </tr>
          
        </tbody>
        <tbody id="">
          <tr>
            <th>Different target of<br>emotion and speaker</th>
            <td><audio src="./audios/sad_man.wav" controls="" style="width:130px"></audio></td>
            <td><audio src="./audios/anger_man.wav" controls="" style="width:130px"></audio></td>
            <td><audio src="./audios/happy_girl.wav" controls="" style="width:130px"></audio></td>
            <td><audio src="./audios/evc/progre/spk_emo_fbank.wav" controls="" style="width:130px"></audio></td>
            <td><audio src="./audios/evc/data2vec/spk_emo_fbank.wav" controls="" style="width:130px"></audio></td>
            <td><audio src="./audios/evc/hubert/spk_emo_fbank.wav" controls="" style="width:130px"></audio></td>
            <td><audio src="./audios/evc/wav2vec/spk_emo_fbank.wav" controls="" style="width:130px"></audio></td>
            <td><audio src="./audios/evc/wavlm/spk_emo_fbank.wav" controls="" style="width:130px"></audio></td>
            <td><audio src="./audios/evc/whisper/spk_emo_fbank.wav" controls="" style="width:130px"></audio></td>
            <td>
              <div style="display: flex; flex-direction: column;">
                <span style="width:130px">Can't control emotion and speaker from different speech</span>
                <div style="border-top: 1px dashed gray; width: 100%; margin: 10px 0;"></div>

                <audio src="./audios/evc/consis_vc/MSP-PODCAST_2894_0284_to_anger_336-364_0349.wav" controls="" style="width:130px"></audio>
                <span>Emotion Target</span>
                
                <!-- 添加虚线 -->
                <div style="border-top: 1px dashed gray; width: 100%; margin: 10px 0;"></div>
                
                <audio src="./audios/evc/consis_vc/MSP-PODCAST_2894_0284_to_0016_000721.wav" controls="" style="width:130px"></audio>
                <span>Speaker Target</span>
            </div>
          </td>
            <td><audio src="./audios/evc/wav2vec_vc/spk_emo_fbank.wav" controls="" style="width:130px"></audio></td>
          </tr>
          
        </tbody>
      </table>
    </div>
  </div>
</div>


<div class="block-style">
  <h2 style="text-align: center">Reconstruction</h2>
  <p>
    Our framework reliably reconstructs high-quality speech based on intermediate representations. This allows for the integration of vector quantization to encode the content and the Transformer encoder's input, both of which are frame-level representations, enabling controllable speech synthesis.
    <br>
    <br>
  </p>
  <div class="english_vc_examples">
    <div class="english_vc active" data-page="1">
      <table class="table" style="margin-top: 20px;">
        <thead>
          <tr>
            <!-- 第一行，合并的cell -->
            <th colspan="1"></th> <!-- 合并Source Speech和Target Speaker的两列 -->
            <th colspan="6">24-layer Pre-trained Model Under Our Framework</th> <!-- 合并ProgRE到Whisper的六列 -->
            <th colspan="2">Baseline methods</th> <!-- 合并ConsistencyVC和Wav2vec-VC的两列 -->
        </tr>
          <tr>
            <th>Source Speech</th>
            <th><b>ProgRE</b></th>
            <th><a >Data2vec</a></th>
            <th><a >HuBERT</a></th>
            <th><a >Wav2vec2.0</a></th>
            <th><a >WavLM</a></th>
            <th><a >Whisper</a></th>
            <th><a >ConsistencyVC</a></th>
            <th><a >Wav2vec-VC</a></th>
          </tr>
        </thead>
        <tbody id="">
          <tr>
            <td><audio src="./audios/rec/MSP-PODCAST_1671_0025_0016.wav" controls="" style="width:130px"></audio></td>
            <td><audio src="./audios/rec/progre/2_MSP-PODCAST_1671_0025_0016_srcspkmsp-924_tgtspkmsp-924_srcemohappy_tgtemohappy.wav" controls="" style="width:130px"></audio></td>
            <td><audio src="./audios/rec/data2vec/2_MSP-PODCAST_1671_0025_0016_srcspkmsp-924_tgtspkmsp-924_srcemohappy_tgtemohappy.wav" controls="" style="width:130px"></audio></td>
            <td><audio src="./audios/rec/hubert/2_MSP-PODCAST_1671_0025_0016_srcspkmsp-924_tgtspkmsp-924_srcemohappy_tgtemohappy.wav" controls="" style="width:130px"></audio></td>
            <td><audio src="./audios/rec/wav2vec/2_MSP-PODCAST_1671_0025_0016_srcspkmsp-924_tgtspkmsp-924_srcemohappy_tgtemohappy.wav" controls="" style="width:130px"></audio></td>
            <td><audio src="./audios/rec/wavlm/2_MSP-PODCAST_1671_0025_0016_srcspkmsp-924_tgtspkmsp-924_srcemohappy_tgtemohappy.wav" controls="" style="width:130px"></audio></td>
            <td><audio src="./audios/rec/whisper/2_MSP-PODCAST_1671_0025_0016_srcspkmsp-924_tgtspkmsp-924_srcemohappy_tgtemohappy.wav" controls="" style="width:130px"></audio></td>
            <td><audio src="./audios/rec/consis_vc/2_MSP-PODCAST_1671_0025_0016_srcspkmsp-924_tgtspkmsp-924_srcemohappy_tgtemohappy.wav" controls="" style="width:130px"></audio></td>
            <td><audio src="./audios/rec/wav2vec_vc/2_MSP-PODCAST_1671_0025_0016_srcspkmsp-924_tgtspkmsp-924_srcemohappy_tgtemohappy.wav" controls="" style="width:130px"></audio></td>
          </tr>
          
        </tbody>
        <tbody id="">
          <tr>
            <td><audio src="./audios/rec/002.wav" controls="" style="width:130px"></audio></td>
            <td><audio src="./audios/rec/progre/3_002_srcspkmead-M026_tgtspkmead-M026_srcemohappy_tgtemohappy.wav" controls="" style="width:130px"></audio></td>
            <td><audio src="./audios/rec/data2vec/3_002_srcspkmead-M026_tgtspkmead-M026_srcemohappy_tgtemohappy.wav" controls="" style="width:130px"></audio></td>
            <td><audio src="./audios/rec/hubert/3_002_srcspkmead-M026_tgtspkmead-M026_srcemohappy_tgtemohappy.wav" controls="" style="width:130px"></audio></td>
            <td><audio src="./audios/rec/wav2vec/3_002_srcspkmead-M026_tgtspkmead-M026_srcemohappy_tgtemohappy.wav" controls="" style="width:130px"></audio></td>
            <td><audio src="./audios/rec/wavlm/3_002_srcspkmead-M026_tgtspkmead-M026_srcemohappy_tgtemohappy.wav" controls="" style="width:130px"></audio></td>
            <td><audio src="./audios/rec/whisper/3_002_srcspkmead-M026_tgtspkmead-M026_srcemohappy_tgtemohappy.wav" controls="" style="width:130px"></audio></td>
            <td><audio src="./audios/rec/consis_vc/3_002_srcspkmead-M026_tgtspkmead-M026_srcemohappy_tgtemohappy.wav" controls="" style="width:130px"></audio></td>
            <td><audio src="./audios/rec/wav2vec_vc/3_002_srcspkmead-M026_tgtspkmead-M026_srcemohappy_tgtemohappy.wav" controls="" style="width:130px"></audio></td>
          </tr>
          
        </tbody>
      </table>
    </div>
  </div>
</div>


<div class="block-style">
  <h2 style="text-align: center">Performance of Flow Predictor</h2>
  <p>
    <!-- The addition of the flow predictor significantly enhances perceptual quality, but it reduces the recognition accuracy of the Whisper model. We hypothesize that this is similar to the artificial artifacts introduced by speech enhancement in robust ASR, as the flow matching process is akin to noise reduction. -->
    Despite the improvements in speech quality, the randomness and artifacts introduced during inference reduce the accuracy of speech recognition models. We believe this reflects a limitation of the evaluation method rather than a flaw in the generation process.

    <div class="custom-spacing">
      <p>Benefits of Flow Predictor:</p>
      <ul>
          <li>In the results with Flow predictor, the acoustic structure (harmonics) of the speech is more complete.</li>
          <li>The result with Flow predictor makes the speech sound less mechanical.</li>
          <li>In summary, Flow Predictor can significantly improve the perceptual quality of speech.</li>
      </ul>
    </div>


    <div class="custom-spacing">
      <p>We speculate that the main reason for the decline in speech recognition and other indicators measured by deep learning models is that the artificial artifacts and randomness come from the inference process of the flow predictor.</p>
      <!-- <ul>
          <li>In the results with Flow predictor, the acoustic structure (harmonics) of the speech is more complete.</li>
          <li>The result with Flow predictor makes the speech sound less mechanical.</li>
          <li>In summary, Flow Predictor can significantly improve the perceptual quality of speech.</li>
      </ul> -->
    </div>

    <br>
    <br>
  </p>
  <div class="english_vc_examples">
    <div class="english_vc active" data-page="1">
      <table class="table" style="margin-top: 20px;">
        <thead>
          
          <tr>
            <th>without Flow Predictor</th>
            <th><b>with Flow Predictor</b></th>
          </tr>
        </thead>
        <tbody id="">
          <tr>
            <!-- 第二列，插入图片 -->
            <td><img src="./audios/abs/1nfm.png" alt="Audio Image 2" style="width:350px; height:200px;"><br>lab: THAT IS ALL I GOT TO SAY ON THAT I AM TIRED OF IT IT IS IRRITATING IT IS VERY CORNY TO ME <br>rec: THAT IS ALL I GOT TO SAY ON THAT I AM TIRED OF IT IT IS IRRITATING IT IS VERY CORNY TO ME<br>WER by Whisper Large V3: <b>0.0%</b> </td>
            <td><img src="./audios/abs/1fm.png" alt="Audio Image 1" style="width:350px; height:200px;"><br>lab: THAT IS ALL I&nbsp;&nbsp;&nbsp;&nbsp;GOT TO SAY ON THAT I AM TIRED OF IT IT IS IRRITATING IT IS VERY CORNY TO ME <br>rec: THAT IS ALL THAT IS&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ON&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;I AM TIRED OF IT IT IS IRRITATING IT IS VERY CORNY TO ME<br>WER by Whisper Large V3: <b>21.74 %</b></td>
        </tr>
        <tr>
          <td><audio src="./audios/abs/635_MSP-PODCAST_3561_0400_srcspkmsp-1765_tgtspkmsp-1765_srcemoneutral_tgtemoneutral-nfm.wav" controls="" style="width:350px"></audio></td>
          <td><audio src="./audios/abs/635_MSP-PODCAST_3561_0400_srcspkmsp-1765_tgtspkmsp-1765_srcemoneutral_tgtemoneutral-fm.wav" controls="" style="width:350px"></audio></td>
        </tr>
          
        </tbody>
      </table>
    </div>
  </div>

  <div class="english_vc_examples">
    <div class="english_vc active" data-page="1">
      <table class="table" style="margin-top: 20px;">
        <thead>
          
          <tr>
            <th>without Flow Predictor</th>
            <th><b>with Flow Predictor</b></th>
          </tr>
        </thead>
        <tbody id="">
          <tr>
            <!-- 第二列，插入图片 -->
            <td><img src="./audios/abs/2nfm.png" alt="Audio Image 2" style="width:350px; height:200px;"><br>lab: THOSE MUSICIANS HARMONIZE MARVELOUSLY<br>rec: THOSE MUSICIANS HARMONIZE MARVELOUSLY<br>WER by Whisper Large V3: <b>0.0%</b> </td>
            <td><img src="./audios/abs/2fm.png" alt="Audio Image 1" style="width:350px; height:200px;"><br>lab: THOSE MUSICIANS HARMONIZE MARVELOUSLY<br>rec: THOSE MUSICIANS HARMONIZE MERRILY&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>WER by Whisper Large V3: <b>25.0%</b></td>
        </tr>
        <tr>
          <td><audio src="./audios/abs/134_004_srcspkmead-W038_tgtspkmead-W038_srcemohappy_tgtemohappy-nfm.wav" controls="" style="width:350px"></audio></td>
          <td><audio src="./audios/abs/134_004_srcspkmead-W038_tgtspkmead-W038_srcemohappy_tgtemohappy-fm.wav" controls="" style="width:350px"></audio></td>
        </tr>
          
        </tbody>
      </table>
    </div>
  </div>

</li>
</ul>


<div class="block-style">

  <h2 style="text-align: center" id="abs">Ablation Study</h2>
  <p>
    Due to space limitations, Table III in the paper only presents the results of the last column, Average. To eliminate any potential misunderstanding for readers, we provide here the complete results for all four tasks. Please note that the structure of our generation module is designed to better utilize the information extracted by the pre-trained disentanglement module, enabling the generation of controllable, high-quality speech. The ability to disentangle speech characteristics is what we aim to evaluate, and we expect this capability to reside in the pre-trained model itself, rather than being the goal of the generation module. 

    <div class="custom-spacing">
      <ul>
          <li>As seen from the last two rows, the progressive generation consistently improves the performance across ERS, SS, and WER.</li>
          <li>A comparison between the first and second rows reveals that the Acoustic Compensator effectively enhances audio quality (DNSMos) and significantly improves the quality of speech reconstruction. Without the Acoustic Compensator, all metrics in the reconstruction task decrease substantially. In the EC, VC, and EVC tasks, it noticeably reduces the WER and enhances the DNSMos, although with a slight decrease in ERS and SS. We believe that this minor sacrifice in conversion characteristics is worthwhile, as it results in higher audio quality and stronger reconstruction capabilities. Furthermore, the first row's performance shows significant improvement compared to two baselines in Table I.</li>
          <li> A comparison between the first and third rows demonstrates that the Flow Predictor significantly enhances audio quality (average DNSMos significantly improves from 2.84 to 3.03). Although this improvement comes with a decline in other metrics, human auditory evaluations suggest that the Flow Predictor introduces distortions imperceptible to the human ear. These distortions, however, negatively impact the performance of evaluation metrics based on deep learning models. For a detailed discussion, please refer to the previous analysis in this page. We consider this a limitation of the evaluation metrics rather than a critical issue of our method. Since high-quality audio for human listeners is the ultimate goal in tasks such as voice conversion and TTS, we opted to include the Flow Predictor, despite its adverse effects on ERS, SS, and WER metrics.</li>
      </ul>
    </div>
  </p>

<table>
  <thead>
    <tr>
      <th>Name</th>
      <th colspan="4">EC</th>
      <th colspan="4">VC</th>
      <th colspan="4">EVC</th>
      <th colspan="4">Reconstruction</th>
      <th colspan="4">Average</th>
    </tr>
    <tr>
      <th></th>
      <th>ERS</th><th>SS</th><th>WER</th><th>DNS</th>
      <th>ERS</th><th>SS</th><th>WER</th><th>DNS</th>
      <th>ERS</th><th>SS</th><th>WER</th><th>DNS</th>
      <th>ERS</th><th>SS</th><th>WER</th><th>DNS</th>
      <th>ERS</th><th>SS</th><th>WER</th><th>DNS</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>whole framework (24-layer ProgRE)</td>
      <td>68.03</td><td>72.49</td><td>4.57</td><td>3.13</td>
      <td>94.02</td><td>67.95</td><td>4.02</td><td>3.05</td>
      <td>68.99</td><td>69.17</td><td>5.21</td><td>2.89</td>
      <td>95.91</td><td>86.85</td><td>4.21</td><td>3.04</td>
      <td>81.74</td><td>74.12</td><td>4.50</td><td>3.03</td>
    </tr>
    <tr>
      <td> - Acoustic Compensator (Comp)</td>
      <td>69.10</td><td>73.26</td><td>5.18</td><td>3.00</td>
      <td>93.95</td><td>69.13</td><td>4.99</td><td>2.95</td>
      <td>70.43</td><td>72.44</td><td>5.68</td><td>2.84</td>
      <td>93.38</td><td>82.24</td><td>6.25</td><td>2.95</td>
      <td>81.72</td><td>74.27</td><td>5.53</td><td>2.93</td>
    </tr>
    <tr>
      <td> - FlowPredictor (Flow)</td>
      <td>69.23</td><td>72.61</td><td>2.20</td><td>2.98</td>
      <td>93.72</td><td>70.68</td><td>2.51</td><td>2.80</td>
      <td>69.24</td><td>72.28</td><td>2.39</td><td>2.58</td>
      <td>96.24</td><td>87.06</td><td>2.00</td><td>3.01</td>
      <td>82.11</td><td>75.66</td><td>2.28</td><td>2.84</td>
    </tr>
    <tr>
      <td> - Flow - Comp</td>
      <td>70.94</td><td>73.99</td><td>2.47</td><td>2.95</td>
      <td>94.04</td><td>71.82</td><td>2.74</td><td>2.76</td>
      <td>70.52</td><td>72.85</td><td>2.61</td><td>2.54</td>
      <td>92.87</td><td>83.69</td><td>3.71</td><td>2.89</td>
      <td>82.09</td><td>75.59</td><td>2.88</td><td>2.79</td>
    </tr>
    <tr>
      <td> - Flow - Comp - Progressive (in generator)</td>
      <td>70.14</td><td>73.46</td><td>2.59</td><td>2.96</td>
      <td>93.97</td><td>71.01</td><td>2.81</td><td>2.77</td>
      <td>69.72</td><td>72.66</td><td>2.77</td><td>2.55</td>
      <td>93.68</td><td>83.44</td><td>3.86</td><td>2.90</td>
      <td>81.88</td><td>75.14</td><td>3.01</td><td>2.80</td>
    </tr>
  </tbody>
</table>
</div>

            
            
</body>
</html>